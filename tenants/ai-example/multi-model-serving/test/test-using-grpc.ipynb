{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f73046ff",
   "metadata": {},
   "source": [
    "# GRPC Inference"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "443e7e73-24cb-4f03-9491-a6edcc24f0cc",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Setup\n",
    "\n",
    "Verify that following variable settings match your deployed model's resource name and grpc URL. The following code assumes that the kube service is in the same namespace, but you could refer to it in full with the namespace, for example: `http://modelmesh-serving.project-name.svc.cluster.local:8008/v2/models/fraud/infer`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db9df000-a171-4652-8160-272f81e49612",
   "metadata": {},
   "outputs": [],
   "source": [
    "# These modules are already installed on Standard Data Science image\n",
    "# !pip install grpcio grpcio-tools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d17b252-7827-4cae-adb0-f98c9d80bcd7",
   "metadata": {},
   "outputs": [],
   "source": [
    "grpc_host = 'modelmesh-serving.ai-example-multi-model-serving.svc.cluster.local'\n",
    "grpc_port = 8033\n",
    "model_name = 'fraud-detection-model'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4269da9e-5683-4531-9a3f-a1cdad42e3af",
   "metadata": {},
   "source": [
    "## Inspect the gRPC Endpoint\n",
    "\n",
    "Check the gRPC endpoint's model metadata:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "545aa5f4-356f-4e70-b7e6-cd352a68927a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('./utils')\n",
    "\n",
    "# grpc_predict_v2_pb2 and grpc_predict_v2_pb2_grpc were created from grpc_predict_v2.proto using protoc\n",
    "import grpc\n",
    "import utils.grpc_predict_v2_pb2 as grpc_predict_v2_pb2\n",
    "import utils.grpc_predict_v2_pb2_grpc as grpc_predict_v2_pb2_grpc\n",
    "\n",
    "\n",
    "channel = grpc.insecure_channel(f\"{grpc_host}:{grpc_port}\")\n",
    "stub = grpc_predict_v2_pb2_grpc.GRPCInferenceServiceStub(channel)\n",
    "\n",
    "request = grpc_predict_v2_pb2.ModelMetadataRequest(name=model_name)\n",
    "response = stub.ModelMetadata(request)\n",
    "response"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd5affbf-36c3-4e17-9788-5fc0904de143",
   "metadata": {},
   "source": [
    "### Request Function\n",
    "\n",
    "Build and submit the gRPC request. \n",
    "\n",
    "Note: You submit the data in the same format that you used for an ONNX inference.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67c1d001-ff99-414a-95d4-5729d5849298",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def grpc_request(data):\n",
    "    # request content building\n",
    "    inputs = []\n",
    "    inputs.append(grpc_predict_v2_pb2.ModelInferRequest().InferInputTensor())\n",
    "    inputs[0].name = \"dense_input\"\n",
    "    inputs[0].datatype = \"FP32\"\n",
    "    inputs[0].shape.extend([1, 5])\n",
    "    inputs[0].contents.fp32_contents.extend(data)\n",
    "    print(inputs)\n",
    "\n",
    "    # request building\n",
    "    request = grpc_predict_v2_pb2.ModelInferRequest()\n",
    "    request.model_name = model_name\n",
    "    request.inputs.extend(inputs)\n",
    "\n",
    "    response = stub.ModelInfer(request)\n",
    "    result_arr = np.frombuffer(response.raw_output_contents[0], dtype=np.float32)\n",
    "    return result_arr"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "911b1015-28b0-4d60-bc17-7b30326b97bc",
   "metadata": {},
   "source": [
    "### Run the Request"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12947866-e0f5-4c72-ba9a-04229b1af990",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = [0.3111400080477545, 1.9459399775518593, 1.0, 0.0, 0.0]\n",
    "prediction = grpc_request(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1e2cbfa-848c-4f9e-891c-45ff8658b673",
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "946f9f1d-b24a-4aa6-b839-f0e8013ef84d",
   "metadata": {},
   "outputs": [],
   "source": [
    "threshhold = 0.995\n",
    "\n",
    "if (prediction > threshhold):\n",
    "    print('fraud')\n",
    "else:\n",
    "    print('not fraud')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
